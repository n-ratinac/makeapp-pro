{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe Face Detection and Face Mesh\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.7)\n",
    "face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1, min_detection_confidence=0.7)\n",
    "\n",
    "def detect_faces(image):\n",
    "    \"\"\"Detect faces in an image using MediaPipe.\"\"\"\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = face_detection.process(image_rgb)\n",
    "    if results.detections:\n",
    "        faces = [detection.location_data.relative_bounding_box for detection in results.detections]\n",
    "        return faces\n",
    "    return []\n",
    "\n",
    "def get_face_landmarks(image, face_box):\n",
    "    \"\"\"Detect facial landmarks in a cropped face image.\"\"\"\n",
    "    h, w, _ = image.shape\n",
    "    ymin = int(face_box.ymin * h)\n",
    "    xmin = int(face_box.xmin * w)\n",
    "    ymax = int((face_box.ymin + face_box.height) * h)\n",
    "    xmax = int((face_box.xmin + face_box.width) * w)\n",
    "    \n",
    "    face_crop = image[ymin:ymax, xmin:xmax]\n",
    "    face_crop_rgb = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(face_crop_rgb)\n",
    "    \n",
    "    landmarks = []\n",
    "    if results.multi_face_landmarks:\n",
    "        for landmarks_list in results.multi_face_landmarks:\n",
    "            landmarks = [(lm.x * face_crop.shape[1], lm.y * face_crop.shape[0]) for lm in landmarks_list.landmark]\n",
    "    return landmarks, face_crop\n",
    "\n",
    "def align_faces_using_homography(src_landmarks, tgt_landmarks, src_face, tgt_face):\n",
    "    \"\"\"Align the target face to the source face using homography.\"\"\"\n",
    "    src_points = np.array(src_landmarks, dtype=np.float32)\n",
    "    tgt_points = np.array(tgt_landmarks, dtype=np.float32)\n",
    "\n",
    "    # Find homography matrix\n",
    "    H, status = cv2.findHomography(tgt_points, src_points)\n",
    "    aligned_face = cv2.warpPerspective(tgt_face, H, (src_face.shape[1], src_face.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return aligned_face\n",
    "\n",
    "def compute_pixel_difference(image1, image2):\n",
    "    \"\"\"Compute the pixel-wise difference between two images.\"\"\"\n",
    "    image1_gray = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    image2_gray = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "    difference = cv2.absdiff(image1_gray, image2_gray)\n",
    "    _, thresholded_diff = cv2.threshold(difference, 25, 255, cv2.THRESH_BINARY)\n",
    "    return difference\n",
    "\n",
    "def main():\n",
    "    # Load images\n",
    "    image_before = cv2.imread('data/after/1.png')\n",
    "    image_after = cv2.imread('data/before/1.png')\n",
    "\n",
    "    # Detect faces\n",
    "    faces_before = detect_faces(image_before)\n",
    "    faces_after = detect_faces(image_after)\n",
    "\n",
    "    if faces_before and faces_after:\n",
    "        # Assume we take the first detected face for alignment\n",
    "        face_box_before = faces_before[0]\n",
    "        face_box_after = faces_after[0]\n",
    "        \n",
    "        # Get landmarks and crop faces\n",
    "        landmarks_before, face_crop_before = get_face_landmarks(image_before, face_box_before)\n",
    "        landmarks_after, face_crop_after = get_face_landmarks(image_after, face_box_after)\n",
    "        \n",
    "        if landmarks_before and landmarks_after:\n",
    "            # Align faces using homography\n",
    "            aligned_after_face = align_faces_using_homography(landmarks_before, landmarks_after, face_crop_before, face_crop_after)\n",
    "            \n",
    "            # Scale faces to the same size\n",
    "            size = (face_crop_before.shape[1], face_crop_before.shape[0])\n",
    "            aligned_after_face = cv2.resize(aligned_after_face, size)\n",
    "            \n",
    "            # Compute pixel difference\n",
    "            pixel_difference = compute_pixel_difference(face_crop_before, aligned_after_face)\n",
    "            \n",
    "            # Display results\n",
    "            cv2.imshow('Face Before Makeup', face_crop_before)\n",
    "            cv2.imshow('Aligned After Makeup Face', aligned_after_face)\n",
    "            cv2.imshow('Pixel Difference', pixel_difference)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "        else:\n",
    "            print(\"Landmarks could not be detected.\")\n",
    "    else:\n",
    "        print(\"Faces could not be detected.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
